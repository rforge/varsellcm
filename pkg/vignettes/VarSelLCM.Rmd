---
title: "Vignette of **VarSelLCM**"
author: "Matthieu Marbac and Mohammed Sedki"
date: "`r format(Sys.time(), '%d %b %Y')`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette of VarSelLCM}
  %\VignetteEngine{knitr::rmarkdown}
---


```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(fig.align="center",
               fig.width=5, fig.height=4.5,
               dev.args=list(pointsize=8))
```

## Introduction
  *VarSelLCM* carries out the variable selection for model-based clustering performed with the Latent Class Model. This model analyzes mixed-type data (data with continuous and/or count and/or categorical variables) with missing values (missing at random) by assuming independence between the observed variables conditionally on components. The one-dimensional marginals of the components follow standard distributions for facilitating both model interpretation and model selection.

  The variable selection is led by an alternated optimization procedure for maximizing the MICL (Maximum Integrated Complete-data Likelihood) criterion. The maximum likelihood inference is done by an EM algorithm for the selected model.  
  
This package also proposes an imputation method for the missing values by taking the expectation of the missing values conditionally on the model, its parameters and on the observed variables.

Tool functions (*summary, print* and *plot*) facilitate the result interpretation.



## Tutorial 1:  benefits of the variable selection
**Loadings**
```{r, comment=""}
# Package loading
library(VarSelLCM)
# Data loading:
# x contains the observed variables
# z the known statu (i.e. 1: absence and 2: presence of heart disease)
data(heart)
z <- heart[,"Class"]
x <- heart[,-13]
```


**Cluster analysis with and without variable selection**
```{r, comment=""}
# Cluster analysis without variable selection
res_without <- VarSelCluster(x, 2, vbleSelec = FALSE)

# Cluster analysis with variable selection (with parallelisation)
res_with <- VarSelCluster(x, 2, nbcores = 2, initModel=40)
```

**Variable selection increases the information criteria**
```{r, comment=""}
# Summary of the model without variable selection
summary(res_without)

# Summary of the model with variable selection
summary(res_with)
```


**Variable selection increases the partitioning accuracy**
```{r, comment=""}
# Confusion matrices: variable selection decreases the misclassification error rate
print(table(z, res_without@partitions@zMAP))
print(table(z, res_with@partitions@zMAP))
```


## Tutorial 2:  dealing with missing values
**Data set loading and missing value adding**
```{r, comment=""}
set.seed(12)
data(SimulHetero)
xmiss <- SimulHetero
xmiss[sample(1:100, 20), 1] <- NA
summary(xmiss)
```

**Cluster analysis with and without missing values**
```{r, comment=""}
res_without <- VarSelCluster(xmiss, 3, vbleSelec = FALSE)
res_with <- VarSelCluster(xmiss, 3)
```

**Information criteria are increased by the variable selection**
```{r, comment=""}
res_without <- VarSelCluster(xmiss, 3, vbleSelec = FALSE)
res_with <- VarSelCluster(xmiss, 3)
```

**Imputation of missing values by using the model parameters**

Function *VarSelImputation()* performs the imputation on
individuals having missing values by taking the expectation of the
missing variables conditionally on the model, its estimates and the
observed variables, as follows
$$
\forall j \notin \mathcal{O}_i, x_{ij}=\mathbb{E}\left[x_{ij} \mid m, \hat{\theta}, x_{i\mathcal{O}_i}\right],
$$
where $x_{i\mathcal{O}_i}=(x_{ij}; j\in\mathcal{O}_i)$. 

```{r, comment=""}
ximput_with <- VarSelImputation(res_with)
ximput_without <- VarSelImputation(res_without)
```

**The quadratic error is decreased by performing the variable selection**
```{r, comment=""}
print(paste("Quadratic error with variable selection:   ",sum((SimulHetero[,1]-ximput_with[,1])**2)))
print(paste("Quadratic error without variable selection:",sum((SimulHetero[,1]-ximput_without[,1])**2)))
```

**Plot of the parameters for putting the light on the discriminative variables**

The method *plot()* illustrates the discriminative power of each variable by class.  The discriminative power of continuous variable $j$ in component $k$ is given by 
$$\int_{R}\Big[\pi_k p(x_j ;\alpha_{kj}, m) - \sum_{\ell \neq k} \dfrac{\pi_\ell}{1-\pi_k} p(x_j ; \alpha_{\ell j}, m) \Big]^2 dx_J. $$
The same quantity is used for categorical and counting variable
replacing integral by sum.

```{r fig.width=6, fig.height=3.5}
# Plot of the parameters
plot(res_with)
```

**Details about the estimates**
```{r, comment=""}
# Show the parameters
print(res_with)
```